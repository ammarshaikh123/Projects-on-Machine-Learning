{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.model_selection import GridSearchCV , train_test_split , cross_val_score\n",
    "from sklearn.metrics import classification_report , confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>250.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>124.500000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.023292</td>\n",
       "      <td>-0.026872</td>\n",
       "      <td>0.167404</td>\n",
       "      <td>0.001904</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>-0.007304</td>\n",
       "      <td>0.032052</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044652</td>\n",
       "      <td>0.126344</td>\n",
       "      <td>0.018436</td>\n",
       "      <td>-0.012092</td>\n",
       "      <td>-0.065720</td>\n",
       "      <td>-0.106112</td>\n",
       "      <td>0.046472</td>\n",
       "      <td>0.006452</td>\n",
       "      <td>0.009372</td>\n",
       "      <td>-0.128952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72.312977</td>\n",
       "      <td>0.480963</td>\n",
       "      <td>0.998354</td>\n",
       "      <td>1.009314</td>\n",
       "      <td>1.021709</td>\n",
       "      <td>1.011751</td>\n",
       "      <td>1.035411</td>\n",
       "      <td>0.955700</td>\n",
       "      <td>1.006657</td>\n",
       "      <td>0.939731</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011416</td>\n",
       "      <td>0.972567</td>\n",
       "      <td>0.954229</td>\n",
       "      <td>0.960630</td>\n",
       "      <td>1.057414</td>\n",
       "      <td>1.038389</td>\n",
       "      <td>0.967661</td>\n",
       "      <td>0.998984</td>\n",
       "      <td>1.008099</td>\n",
       "      <td>0.971219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.319000</td>\n",
       "      <td>-2.931000</td>\n",
       "      <td>-2.477000</td>\n",
       "      <td>-2.359000</td>\n",
       "      <td>-2.566000</td>\n",
       "      <td>-2.845000</td>\n",
       "      <td>-2.976000</td>\n",
       "      <td>-3.444000</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.804000</td>\n",
       "      <td>-2.443000</td>\n",
       "      <td>-2.757000</td>\n",
       "      <td>-2.466000</td>\n",
       "      <td>-3.287000</td>\n",
       "      <td>-3.072000</td>\n",
       "      <td>-2.634000</td>\n",
       "      <td>-2.776000</td>\n",
       "      <td>-3.211000</td>\n",
       "      <td>-3.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>62.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.644750</td>\n",
       "      <td>-0.739750</td>\n",
       "      <td>-0.425250</td>\n",
       "      <td>-0.686500</td>\n",
       "      <td>-0.659000</td>\n",
       "      <td>-0.643750</td>\n",
       "      <td>-0.675000</td>\n",
       "      <td>-0.550750</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-0.510500</td>\n",
       "      <td>-0.535750</td>\n",
       "      <td>-0.657000</td>\n",
       "      <td>-0.818500</td>\n",
       "      <td>-0.821000</td>\n",
       "      <td>-0.605500</td>\n",
       "      <td>-0.751250</td>\n",
       "      <td>-0.550000</td>\n",
       "      <td>-0.754250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>124.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.015500</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>-0.016500</td>\n",
       "      <td>-0.023000</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.060500</td>\n",
       "      <td>0.183500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.091000</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>-0.021000</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.079500</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>-0.009000</td>\n",
       "      <td>-0.132500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>186.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677000</td>\n",
       "      <td>0.620750</td>\n",
       "      <td>0.805000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.660500</td>\n",
       "      <td>0.783250</td>\n",
       "      <td>0.766250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.797250</td>\n",
       "      <td>0.804250</td>\n",
       "      <td>0.631500</td>\n",
       "      <td>0.650250</td>\n",
       "      <td>0.739500</td>\n",
       "      <td>0.493000</td>\n",
       "      <td>0.683000</td>\n",
       "      <td>0.794250</td>\n",
       "      <td>0.654250</td>\n",
       "      <td>0.503250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>249.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.567000</td>\n",
       "      <td>2.419000</td>\n",
       "      <td>3.392000</td>\n",
       "      <td>2.771000</td>\n",
       "      <td>2.901000</td>\n",
       "      <td>2.793000</td>\n",
       "      <td>2.546000</td>\n",
       "      <td>2.846000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.865000</td>\n",
       "      <td>2.801000</td>\n",
       "      <td>2.736000</td>\n",
       "      <td>2.596000</td>\n",
       "      <td>2.226000</td>\n",
       "      <td>3.131000</td>\n",
       "      <td>3.236000</td>\n",
       "      <td>2.626000</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>2.771000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id      target           0           1           2           3  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean   124.500000    0.640000    0.023292   -0.026872    0.167404    0.001904   \n",
       "std     72.312977    0.480963    0.998354    1.009314    1.021709    1.011751   \n",
       "min      0.000000    0.000000   -2.319000   -2.931000   -2.477000   -2.359000   \n",
       "25%     62.250000    0.000000   -0.644750   -0.739750   -0.425250   -0.686500   \n",
       "50%    124.500000    1.000000   -0.015500    0.057000    0.184000   -0.016500   \n",
       "75%    186.750000    1.000000    0.677000    0.620750    0.805000    0.720000   \n",
       "max    249.000000    1.000000    2.567000    2.419000    3.392000    2.771000   \n",
       "\n",
       "                4           5           6           7     ...             290  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000     ...      250.000000   \n",
       "mean     0.001588   -0.007304    0.032052    0.078412     ...        0.044652   \n",
       "std      1.035411    0.955700    1.006657    0.939731     ...        1.011416   \n",
       "min     -2.566000   -2.845000   -2.976000   -3.444000     ...       -2.804000   \n",
       "25%     -0.659000   -0.643750   -0.675000   -0.550750     ...       -0.617000   \n",
       "50%     -0.023000    0.037500    0.060500    0.183500     ...        0.067500   \n",
       "75%      0.735000    0.660500    0.783250    0.766250     ...        0.797250   \n",
       "max      2.901000    2.793000    2.546000    2.846000     ...        2.865000   \n",
       "\n",
       "              291         292         293         294         295         296  \\\n",
       "count  250.000000  250.000000  250.000000  250.000000  250.000000  250.000000   \n",
       "mean     0.126344    0.018436   -0.012092   -0.065720   -0.106112    0.046472   \n",
       "std      0.972567    0.954229    0.960630    1.057414    1.038389    0.967661   \n",
       "min     -2.443000   -2.757000   -2.466000   -3.287000   -3.072000   -2.634000   \n",
       "25%     -0.510500   -0.535750   -0.657000   -0.818500   -0.821000   -0.605500   \n",
       "50%      0.091000    0.057500   -0.021000   -0.009000   -0.079500    0.009500   \n",
       "75%      0.804250    0.631500    0.650250    0.739500    0.493000    0.683000   \n",
       "max      2.801000    2.736000    2.596000    2.226000    3.131000    3.236000   \n",
       "\n",
       "              297         298         299  \n",
       "count  250.000000  250.000000  250.000000  \n",
       "mean     0.006452    0.009372   -0.128952  \n",
       "std      0.998984    1.008099    0.971219  \n",
       "min     -2.776000   -3.211000   -3.500000  \n",
       "25%     -0.751250   -0.550000   -0.754250  \n",
       "50%      0.005500   -0.009000   -0.132500  \n",
       "75%      0.794250    0.654250    0.503250  \n",
       "max      2.626000    3.530000    2.771000  \n",
       "\n",
       "[8 rows x 302 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>250</td>\n",
       "      <td>0.500</td>\n",
       "      <td>-1.033</td>\n",
       "      <td>-1.595</td>\n",
       "      <td>0.309</td>\n",
       "      <td>-0.714</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.535</td>\n",
       "      <td>-0.129</td>\n",
       "      <td>-0.687</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>-2.628</td>\n",
       "      <td>-0.845</td>\n",
       "      <td>2.078</td>\n",
       "      <td>-0.277</td>\n",
       "      <td>2.132</td>\n",
       "      <td>0.609</td>\n",
       "      <td>-0.104</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>251</td>\n",
       "      <td>0.776</td>\n",
       "      <td>0.914</td>\n",
       "      <td>-0.494</td>\n",
       "      <td>1.347</td>\n",
       "      <td>-0.867</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.578</td>\n",
       "      <td>-0.313</td>\n",
       "      <td>0.203</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.683</td>\n",
       "      <td>-0.066</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.606</td>\n",
       "      <td>-0.353</td>\n",
       "      <td>-1.133</td>\n",
       "      <td>-3.138</td>\n",
       "      <td>0.281</td>\n",
       "      <td>-0.625</td>\n",
       "      <td>-0.761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>1.750</td>\n",
       "      <td>0.509</td>\n",
       "      <td>-0.057</td>\n",
       "      <td>0.835</td>\n",
       "      <td>-0.476</td>\n",
       "      <td>1.428</td>\n",
       "      <td>-0.701</td>\n",
       "      <td>-2.009</td>\n",
       "      <td>-1.378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094</td>\n",
       "      <td>0.351</td>\n",
       "      <td>-0.607</td>\n",
       "      <td>-0.737</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.135</td>\n",
       "      <td>-1.327</td>\n",
       "      <td>2.463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>253</td>\n",
       "      <td>-0.556</td>\n",
       "      <td>-1.855</td>\n",
       "      <td>-0.682</td>\n",
       "      <td>0.578</td>\n",
       "      <td>1.592</td>\n",
       "      <td>0.512</td>\n",
       "      <td>-1.419</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.336</td>\n",
       "      <td>-0.787</td>\n",
       "      <td>0.255</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.836</td>\n",
       "      <td>0.916</td>\n",
       "      <td>2.411</td>\n",
       "      <td>1.053</td>\n",
       "      <td>-1.601</td>\n",
       "      <td>-1.529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>254</td>\n",
       "      <td>0.754</td>\n",
       "      <td>-0.245</td>\n",
       "      <td>1.173</td>\n",
       "      <td>-1.623</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.370</td>\n",
       "      <td>0.781</td>\n",
       "      <td>-1.763</td>\n",
       "      <td>-1.432</td>\n",
       "      <td>...</td>\n",
       "      <td>2.184</td>\n",
       "      <td>-1.090</td>\n",
       "      <td>0.216</td>\n",
       "      <td>1.186</td>\n",
       "      <td>-0.143</td>\n",
       "      <td>0.322</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.156</td>\n",
       "      <td>-1.153</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    id      0      1      2      3      4      5      6      7      8  ...    \\\n",
       "0  250  0.500 -1.033 -1.595  0.309 -0.714  0.502  0.535 -0.129 -0.687  ...     \n",
       "1  251  0.776  0.914 -0.494  1.347 -0.867  0.480  0.578 -0.313  0.203  ...     \n",
       "2  252  1.750  0.509 -0.057  0.835 -0.476  1.428 -0.701 -2.009 -1.378  ...     \n",
       "3  253 -0.556 -1.855 -0.682  0.578  1.592  0.512 -1.419  0.722  0.511  ...     \n",
       "4  254  0.754 -0.245  1.173 -1.623  0.009  0.370  0.781 -1.763 -1.432  ...     \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0 -0.088 -2.628 -0.845  2.078 -0.277  2.132  0.609 -0.104  0.312  0.979  \n",
       "1 -0.683 -0.066  0.025  0.606 -0.353 -1.133 -3.138  0.281 -0.625 -0.761  \n",
       "2 -0.094  0.351 -0.607 -0.737 -0.031  0.701  0.976  0.135 -1.327  2.463  \n",
       "3 -0.336 -0.787  0.255 -0.031 -0.836  0.916  2.411  1.053 -1.601 -1.529  \n",
       "4  2.184 -1.090  0.216  1.186 -0.143  0.322 -0.068 -0.156 -1.153  0.825  \n",
       "\n",
       "[5 rows x 301 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7 , 0.72, 0.68, 0.8 , 0.74])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X=train.drop(['id','target'],axis=1)\n",
    "y=train.target\n",
    "\n",
    "clf2 = LogisticRegression(class_weight='balanced', solver='liblinear', penalty ='l1',C=0.8).fit(X, y)\n",
    "scores = cross_val_score(clf2, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.72, 0.7 , 0.64, 0.76, 0.64])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "X=train.drop(['id','target'],axis=1)\n",
    "y=train.target\n",
    "\n",
    "clf3 = SGDClassifier(alpha=0.008, average=False, class_weight=None,\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "       validation_fraction=0.1, verbose=0, warm_start=False).fit(X, y)\n",
    "scores = cross_val_score(clf3, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6 , 0.68, 0.7 , 0.7 , 0.7 ])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "X=train.drop(['id','target'],axis=1)\n",
    "y=train.target\n",
    "\n",
    "clf4 = GradientBoostingClassifier(loss='deviance', learning_rate=0.007, n_estimators=200,min_samples_split=2,\n",
    "                                  validation_fraction=0.1,tol=0.0001).fit(X, y)\n",
    "scores = cross_val_score(clf4, X, y, cv=5)\n",
    "scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        90\n",
      "         1.0       1.00      1.00      1.00       160\n",
      "\n",
      "   micro avg       1.00      1.00      1.00       250\n",
      "   macro avg       1.00      1.00      1.00       250\n",
      "weighted avg       1.00      1.00      1.00       250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_predict= clf3.predict(X)\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict= 0.5*clf2.predict_proba(test.drop('id',axis=1))[:,1] +  0.2*clf3.predict_proba(test.drop('id',axis=1))[:,1] +0.3*clf4.predict_proba(test.drop('id',axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict=clf3.predict_proba(test.drop('id',axis=1))[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=pd.read_csv('test.csv')\n",
    "ids = ss['id']\n",
    "\n",
    "submission_file = open(\"overfit.csv\", \"w\")\n",
    "\n",
    "import csv as csv\n",
    "\n",
    "open_file_object = csv.writer(submission_file)\n",
    "\n",
    "# Write the header of the csv\n",
    "open_file_object.writerow([\"id\",\"target\"])\n",
    "\n",
    "# Write the rows of the csv\n",
    "open_file_object.writerows(zip(ids, test_predict))\n",
    "\n",
    "# Close the file\n",
    "submission_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[]\n",
    "for i in train.drop(['id','target'],axis=1).columns:\n",
    "    \n",
    "    a.append(train[i].corr(train['target']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "d={'col1':a}\n",
    "d=pd.DataFrame(data=d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([  4,  16,  39,  43,  63,  73,  80,  82,  90,  91,  98, 108, 117,\n",
       "            127, 129, 133, 134, 150, 165, 189, 194, 209, 217, 220, 230, 237,\n",
       "            239, 252, 258, 276, 295, 298],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[d.values<-0.1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=train.drop(['4',  '16',  '39',  '43',  '63',  '73',  '80',  '82',  '90',  '91',  '98', '108', '117',\n",
    "            '127', '129', '133', '134', '150', '165', '189', '194', '209', '217', '220', '230', '237',\n",
    "            '239', '252', '258', '276', '295', '298'],axis=1)\n",
    "\n",
    "N_test=test.drop(['4',  '16',  '39',  '43',  '63',  '73',  '80',  '82',  '90',  '91',  '98', '108', '117',\n",
    "            '127', '129', '133', '134', '150', '165', '189', '194', '209', '217', '220', '230', '237',\n",
    "            '239', '252', '258', '276', '295', '298'],axis=1)\n",
    "y=X.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.68, 0.66, 0.66, 0.6 , 0.6 ])"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "#X=X.drop(['id','target'],axis=1)\n",
    "\n",
    "\n",
    "clf2 = LogisticRegression(class_weight='balanced', solver='liblinear', penalty ='l1',C=0.122).fit(X, y)\n",
    "scores = cross_val_score(clf2, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64, 0.66, 0.68, 0.72, 0.7 ])"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "clf4 = GradientBoostingClassifier(loss='deviance', learning_rate=0.0042, n_estimators=200,min_samples_split=2,\n",
    "                                  validation_fraction=0.1,tol=0.0001).fit(X, y)\n",
    "scores = cross_val_score(clf4, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62, 0.6 , 0.58, 0.72, 0.6 ])"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "\n",
    "clf3 = SGDClassifier(alpha=0.0092, average=False, class_weight=None,\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "       validation_fraction=0.1, verbose=0, warm_start=False).fit(X, y)\n",
    "scores = cross_val_score(clf3, X, y, cv=5)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict= clf2.predict_proba(N_test.drop('id',axis=1))[:,1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss=pd.read_csv('test.csv')\n",
    "ids = ss['id']\n",
    "\n",
    "submission_file = open(\"overfit.csv\", \"w\")\n",
    "\n",
    "import csv as csv\n",
    "\n",
    "open_file_object = csv.writer(submission_file)\n",
    "\n",
    "# Write the header of the csv\n",
    "open_file_object.writerow([\"id\",\"target\"])\n",
    "\n",
    "# Write the rows of the csv\n",
    "open_file_object.writerows(zip(ids, test_predict))\n",
    "\n",
    "# Close the file\n",
    "submission_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
